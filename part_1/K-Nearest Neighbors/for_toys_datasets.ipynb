{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод k-ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as dts\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import timeit\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Разбиваем датасет на две части: для теста и для данных проверки*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def split_dataset(data):\n",
    "    len_mass = len(data.data) # длина массива данных\n",
    "    mass_sort = [i for i in range(len_mass)] # массив индексов\n",
    "    random.shuffle(mass_sort) # Рандомно сортируем индексы\n",
    "\n",
    "    len_determine = int(len_mass * 0.7)\n",
    "    # list_determine = [len_mass - len_determine, len_determine]\n",
    "    datasets_learn = [[data.data[i], data.target[i]] for i in mass_sort[:len_determine]] # Первые 70 процентов добавляем для обучение,\n",
    "    datasets_test = [[data.data[i], data.target[i]] for i in mass_sort[len_determine:]] # остальные для теста.\n",
    "    return datasets_learn, datasets_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Разбиваем датасет на две части: для теста и для данных проверки*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Нормализуем данные*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@numba.njit\n",
    "def standartization(X):\n",
    "    return (X - X.min(axis = 0)) / (X.max(axis = 0) - X.min(axis = 0))\n",
    "    # return (X - X.min()) / (X.max() - X.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Метрики*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вход el1 = [el1, el2, ... , eln]\n",
    "# def l1(el1, el2):\n",
    "#     return sum([abs(k - v) for k, v in list(zip(el1, el2))])\n",
    "\n",
    "# def l2(el1, el2):\n",
    "#     return sum([(k - v)**2 for k, v in list(zip(el1, el2))]) ** 0.5\n",
    "@numba.njit\n",
    "def l1(el1, el2): # manhattan\n",
    "    sum_el = 0\n",
    "    for k, v in list(zip(el1, el2)):\n",
    "        sum_el += abs(k - v)\n",
    "    return sum_el\n",
    "\n",
    "@numba.njit\n",
    "def l2(el1, el2): # euclidean\n",
    "    sum_el = 0\n",
    "    for k, v in list(zip(el1, el2)):\n",
    "        sum_el += (k - v) ** 2\n",
    "    return sum_el ** 0.5\n",
    "\n",
    "@numba.njit\n",
    "def l_infinity(el1, el2): # chebyshev\n",
    "    max_len = 0\n",
    "    for k, v in list(zip(el1, el2)):\n",
    "        if abs(k - v) > max_len:\n",
    "            max_len = abs(k - v)\n",
    "    return max_len\n",
    "    # return max([abs(k - v) for k, v in list(zip(el1, el2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Метод k-ближайших соседей*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_class(mass_n):\n",
    "    count = Counter(mass_n)\n",
    "    return max(count, key = count.get)\n",
    "\n",
    "def k_nearest_neightbors(x_train, x, y_train, metric = l1, n = 4):\n",
    "    neightbors = np.array([metric(x, y) for y in x_train]).argsort()[:n]\n",
    "    rez = choice_class([y_train[j] for j in neightbors])\n",
    "    return rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def check_forecast(y_test, forecast):\n",
    "    target_rez = len(y_test)\n",
    "    forecast_rez = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == forecast[i]:\n",
    "            forecast_rez += 1\n",
    "\n",
    "    return forecast_rez / target_rez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for i, name_dts in [(dts.load_iris, \"Iris plants dataset\"),\n",
    "                        (dts.load_digits, \"Optical recognition of handwritten digits dataset\"),\n",
    "                        (dts.load_wine,\"Wine recognition dataset\"),\n",
    "                        (dts.load_breast_cancer, \"Breast cancer wisconsin (diagnostic) dataset\")]:\n",
    "\n",
    "        data = i()\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, train_size = 0.7, random_state = 42)\n",
    "\n",
    "        x_train = standartization(x_train)\n",
    "        x_test = standartization(x_test)\n",
    "\n",
    "        greatest_rez = [0, 0, 0]\n",
    "\n",
    "        for n in range(4, 10):\n",
    "            for m in [l1, l2, l_infinity]:\n",
    "                rez = np.array(range(x_test.shape[0]))\n",
    "                for i in range(x_test.shape[0]):\n",
    "                    rez[i] = k_nearest_neightbors(x_train, x_test[i], y_train, m, n) == y_test[i] if 1 else 0\n",
    "\n",
    "                answer = sum(rez) / y_test.shape[0] # scheck_forecast(y_test, rez)\n",
    "                if greatest_rez[0] < answer:\n",
    "                    greatest_rez = [answer, m, n]\n",
    "                # logreg.predict(X_test) # Прогнозируемые данные\n",
    "        print(f\"Обучение на данных {name_dts} с метрикой {greatest_rez[1].__name__} для {greatest_rez[2]} ближайших соседей: {greatest_rez[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение на данных Iris plants dataset с метрикой l2 для 7 ближайших соседей: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuzin\\AppData\\Local\\Temp/ipykernel_13936/3513667991.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (X - X.min(axis = 0)) / (X.max(axis = 0) - X.min(axis = 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение на данных Optical recognition of handwritten digits dataset с метрикой l_infinity для 5 ближайших соседей: 0.9777777777777777\n",
      "Обучение на данных Wine recognition dataset с метрикой l1 для 4 ближайших соседей: 0.9814814814814815\n",
      "Обучение на данных Breast cancer wisconsin (diagnostic) dataset с метрикой l2 для 7 ближайших соседей: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f3276811286a09a4a5800c96bcffd2991fef064f3f472c3248f5fe31bf08715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
