{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение с подкрепление тестирование"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выполнил Кузин Мирослав**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mancala import Kalah\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Болваны**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Есть ошибки, исправить\n",
    "def do_simple_bot_step(state: torch.Tensor) -> int:\n",
    "    nonzero_state_indexs = torch.nonzero(state[:6]).flatten()\n",
    "    rez = nonzero_state_indexs[torch.randint(0, len(nonzero_state_indexs), (1,))[0]]\n",
    "    return rez + 1\n",
    "\n",
    "\n",
    "# Бот МАСТЕР  захвата\n",
    "def do_prof_bot_step(state: torch.Tensor) -> int:\n",
    "    nonzero_state_indexs = torch.nonzero(state[:6]).flatten()\n",
    "    state_copy = state.clone()\n",
    "    captured = []\n",
    "    additional_moves = []\n",
    "    for cursor in nonzero_state_indexs:\n",
    "        cursor = int(cursor)\n",
    "        n = int(cursor)\n",
    "        temp = int(state_copy[cursor])\n",
    "        state_copy[cursor] = 0\n",
    "        while temp > 0:\n",
    "            temp -= 1\n",
    "            if cursor in range(0, 6):\n",
    "                cursor += 1\n",
    "            elif cursor == 6:\n",
    "                cursor = 13\n",
    "            elif cursor in range(9, 14):\n",
    "                cursor -= 1\n",
    "            elif cursor == 8:\n",
    "                cursor = 0\n",
    "\n",
    "            state_copy[cursor] += 1\n",
    "\n",
    "        if cursor == 6:\n",
    "            additional_moves.append(n)\n",
    "\n",
    "        if cursor < 6 and state_copy[cursor] == 1 and state_copy[cursor%6-6] != 0:\n",
    "            state_copy[6] += sum([state_copy[cursor], state_copy[cursor%6-6]])\n",
    "            captured.append((n, sum([state_copy[cursor], state_copy[cursor%6-6]])))\n",
    "        state_copy = state.clone()\n",
    "\n",
    "\n",
    "    if captured != []:\n",
    "        rez_ind = sorted(captured, key=lambda x: x[1])\n",
    "        rez = rez_ind[-1][0]\n",
    "    elif additional_moves != []:\n",
    "        rez = additional_moves[torch.randint(0, len(additional_moves), (1,))[0]]\n",
    "    else:\n",
    "        rez = nonzero_state_indexs[torch.randint(0, len(nonzero_state_indexs), (1,))[0]]\n",
    "    return rez + 1\n",
    "\n",
    "\n",
    "do_simple_bot_step(torch.Tensor([1, 0, 1, 0, 0, 0, 0]))\n",
    "print(do_prof_bot_step(torch.Tensor([6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Модель**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"Kuzin_M_A_4.6_model2_winner_test_2_10_float.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=14, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=24, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=24, out_features=6, bias=True)\n",
       "  (5): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Настройка тестирования**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.9094e-07, 7.8492e-01, 2.1507e-01, 1.0223e-05, 6.6190e-10, 8.4509e-11],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка работы модели\n",
    "game = Kalah()\n",
    "# model.to(device)\n",
    "model.to(torch.float)\n",
    "\n",
    "print(game.get_general_state())\n",
    "model(game.get_state().to(torch.float))\n",
    "# tensor([1.4313e-03, 9.9306e-01, 5.4998e-03, 6.9316e-06, 2.3116e-06, 2.4980e-08],\n",
    "#        grad_fn=<SoftmaxBackward0>)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Награды и штрафы*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Второй этап обучения\n",
    "winner_reward_stage_2 = 10\n",
    "loser_reward_stage_2 = -10\n",
    "draw_reward_stage_2 = -5\n",
    "bad_step_reward_stage_2 = -0.5 # общий\n",
    "good_step_reward_stage_2 = 0.5\n",
    "good_step_captured_reward_stage_1 = 1\n",
    "\n",
    "# Первый этап обучения\n",
    "winner_reward_stage_1 = 1e-3\n",
    "loser_reward_stage_1 = -1e-3\n",
    "draw_reward_stage_1 = -0.5e-3\n",
    "bad_step_reward_stage_1 = -25 # общий\n",
    "good_step_reward_stage_1 = 1\n",
    "good_step_captured_reward_stage_1 = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тестирование модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.757\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "game = Kalah()\n",
    "episodes_count = 1000\n",
    "neuronet_walker_queue = 1\n",
    "count_win_neuronet = 0\n",
    "draw_count = 0\n",
    "count_choisen_zero = 0\n",
    "bad_choise = []\n",
    "rezult_step = \"Хороший ход!\"\n",
    "\n",
    "och = []\n",
    "\n",
    "for episode in range(episodes_count):\n",
    "    game.set_new_game()\n",
    "    if episode % 2:\n",
    "        old_player_making_step = game.get_player_making_step()\n",
    "        neuronet_walker_queue = 2\n",
    "        while not game.get_game_over() and old_player_making_step == game.get_player_making_step():\n",
    "            # bot_action = do_prof_bot_step(game.get_state())\n",
    "            bot_action = do_simple_bot_step(game.get_state())\n",
    "            # print(\"Бот делает ход, выбор\", bot_action)\n",
    "            rezult_step = game.take_step(bot_action)\n",
    "            # game.print_state()\n",
    "            # print(\"Ходит игрок \", game.get_player_making_step())\n",
    "            # print(\"bot took step\", game.get_player_making_step(), \"Был выбор\", bot_action, rezult_step)\n",
    "    else:\n",
    "        neuronet_walker_queue = 1\n",
    "\n",
    "    while not game.get_game_over():\n",
    "\n",
    "        # Выбор хода\n",
    "        probs = model(game.get_state().to(torch.float))\n",
    "        action = probs.argmax()\n",
    "\n",
    "        while action in bad_choise:\n",
    "            probs[probs.argmax()] = 0\n",
    "            action = probs.argmax()\n",
    "        # action = do_prof_bot_step(game.get_state())\n",
    "\n",
    "        # Выбор награды и выполнение хода\n",
    "        reward = 0\n",
    "        old_state = game.get_state().to(torch.float)\n",
    "        old_player_making_step = game.get_player_making_step()\n",
    "\n",
    "        rezult_step = game.take_step(action + 1) # + 1)\n",
    "        if rezult_step == \"Куча пустая, выберите другую!\":\n",
    "            count_choisen_zero += 1\n",
    "            # reward = bad_step_reward_stage_1\n",
    "\n",
    "            print(\"Номер эпизода происшествия:\", episode)\n",
    "            # print(\"Выбор нейронки: \", action.data + 1)\n",
    "            # print(\"Номер хода\", neuronet_walker_queue, game.get_player_making_step())\n",
    "            # game.print_state()\n",
    "            bad_choise.append(action)\n",
    "        else:\n",
    "            # print(\"Neuronet took step\", game.get_player_making_step(), \"Был выбор\", action + 1, rezult_step)\n",
    "            # print(\"state:\")\n",
    "            # game.print_state()\n",
    "            # print(\"Ходит игрок \", game.get_player_making_step())\n",
    "            bad_choise = []\n",
    "        # elif rezult_step == \"Хороший ход!\":\n",
    "        #     reward = good_step_reward_stage_1\n",
    "        # elif rezult_step == \"Хороший ход! Захват!\":\n",
    "        #     reward = good_step_captured_reward_stage_1\n",
    "\n",
    "        while not game.get_game_over() and old_player_making_step != game.get_player_making_step():\n",
    "            bot_action = do_simple_bot_step(game.get_state())\n",
    "            # print(\"Бот делает ход, выбор\", bot_action)\n",
    "            rezult_step = game.take_step(bot_action)\n",
    "            # game.print_state()\n",
    "            # print(\"Ходит игрок \", game.get_player_making_step())\n",
    "            if rezult_step == \"Куча пустая, выберите другую!\":\n",
    "                print(\"Bot took step\", game.get_player_making_step(), \"Был выбор\", bot_action, rezult_step)\n",
    "            # print(\"bot took step\", game.get_player_making_step(), \"Был выбор\", bot_action, rezult_step)\n",
    "\n",
    "\n",
    "    if game.get_winner() != None:\n",
    "        # st = game.get_general_state()\n",
    "        # # if episode%2:\n",
    "        # #     print(torch.flip(st, [0]))\n",
    "        # #     print(torch.flip(st, dims=(0,)))\n",
    "        # och.append(st[:7].sum() -st[7:].sum())\n",
    "        # count_win_neuronet += 1 if st[:7].sum() -st[7:].sum() > 0 else 0\n",
    "        if game.get_winner() != 0:\n",
    "            if neuronet_walker_queue == game.get_winner():\n",
    "                count_win_neuronet += 1\n",
    "        #         reward += winner_reward_stage_1\n",
    "        #     else:\n",
    "        #         reward += loser_reward_stage_1\n",
    "        # else:\n",
    "        #     reward += draw_reward_stage_1\n",
    "        #     draw_count += 1\n",
    "# OCH = torch.Tensor(och)\n",
    "# print(f'Победы: {torch.where(OCH > 0, torch.ones(OCH.shape),torch.zeros(OCH.shape)).sum()}')\n",
    "\n",
    "    # print(\"Очередь хода нейронки\", neuronet_walker_queue)\n",
    "    # print(\"Результат:\", game.get_player_winner(), 'k', game.get_winner())\n",
    "    # print(\"Номер попытки:\", episode)\n",
    "    # print(\"Награда/Штраф:\", reward)\n",
    "\n",
    "    # print(episode)\n",
    "\n",
    "print(count_choisen_zero)\n",
    "print(count_win_neuronet/episodes_count)\n",
    "print(draw_count/episodes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=14, out_features=42, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=42, out_features=6, bias=True)\n",
       "  (3): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./l0l_test_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Input Tensor:  tensor([ 4,  5,  0, 25, 14])\n",
      "\n",
      "\n",
      "Computed Entropy:  tensor(-131.0111)\n"
     ]
    }
   ],
   "source": [
    "# creating a 1D tensor\n",
    "tens = torch.tensor([4, 5, 0, 25, 14])\n",
    "\n",
    "# Display tensor\n",
    "print(\"\\n\\nInput Tensor: \", tens)\n",
    "\n",
    "# compute the element-wise entropy of\n",
    "# input tensor\n",
    "entr = torch.special.entr(tens).sum()\n",
    "\n",
    "# Display result\n",
    "print(\"\\n\\nComputed Entropy: \", entr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d71e8b1932faf56dee17752329eeb73c746bdacdb1acbdc067bcd5bd3a88241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
